{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instantiated a global camera object!\n",
      "Captured 1 frame.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "write() argument must be str, not numpy.ndarray",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-9854f4efdb29>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"../ML Data/{i}.txt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"w+\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0mconsole\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: write() argument must be str, not numpy.ndarray"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "\n",
    "import car\n",
    "from auto import console\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables\n",
    "cv2.setNumThreads(0)\n",
    "\n",
    "blue = [75, 110, 240]\n",
    "diff = 20\n",
    "\n",
    "crop_height = 70\n",
    "crop_left = 60\n",
    "crop_right = 60\n",
    "\n",
    "# Be aware that opencv loads image in BGR format,\n",
    "# that's why the color values have been adjusted here:\n",
    "boundaries = [([blue[2], blue[1]-diff, blue[0]-diff],\n",
    "        [blue[2]+diff, blue[1]+diff, blue[0]+diff])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions\n",
    "\n",
    "def crop(img):\n",
    "    \"\"\"\n",
    "    Camera captures 240 pixels of height and 320 of width\n",
    "    Shape is (240, 320, 3)\n",
    "    \"\"\"\n",
    "    return img[-crop_height:, crop_left:-crop_right]\n",
    "\n",
    "\n",
    "def scale(img, scalePercent):\n",
    "    # Calculate the new dimensions\n",
    "    width = int(img.shape[1] * scalePercent)\n",
    "    height = int(img.shape[0] * scalePercent)\n",
    "    newSize = (width, height)\n",
    "\n",
    "    # Resize the image:\n",
    "    img = cv2.resize(img, newSize, None, None, None, cv2.INTER_AREA)\n",
    "    return img\n",
    "\n",
    "\n",
    "def percent_blue(img):\n",
    "    for (lower, upper) in boundaries:\n",
    "\n",
    "        # You get the lower and upper part of the interval:\n",
    "        lower = np.array(lower, dtype=np.uint8)\n",
    "        upper = np.array(upper, dtype=np.uint8)\n",
    "\n",
    "        # cv2.inRange is used to binarize (i.e., render in white/black) an image\n",
    "        # All the pixels that fall inside your interval [lower, uipper] will be white\n",
    "        # All the pixels that do not fall inside this interval will\n",
    "        # be rendered in black, for all three channels:\n",
    "        mask = cv2.inRange(img, lower, upper)\n",
    "\n",
    "        # Now, you AND the mask and the input image\n",
    "        # All the pixels that are white in the mask will\n",
    "        # survive the AND operation, all the black pixels\n",
    "        # will remain black\n",
    "        output = cv2.bitwise_and(img, img, mask=mask)\n",
    "\n",
    "        # You can use the mask to count the number of white pixels.\n",
    "        # Remember that the white pixels in the mask are those that\n",
    "        # fall in your defined range, that is, every white pixel corresponds\n",
    "        # to a blue pixel. Divide by the image size and you got the\n",
    "        # percentage of blue pixels in the original image:\n",
    "        ratio_blue = cv2.countNonZero(mask)/(img.size/3)\n",
    "\n",
    "        # This is the color percent calculation, considering the resize I did earlier.\n",
    "        colorPercent = (ratio_blue * 100) / scalePercent\n",
    "\n",
    "        return colorPercent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main logic\n",
    "\n",
    "frame = car.capture()\n",
    "img = crop(frame)\n",
    "\n",
    "percentage = percent_blue(img)\n",
    "console.print(percentage)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
